//
//  OpCommonUtils.hpp
//  MNN
//
//  Created by MNN on 2020/03/08.
//  Copyright Â© 2018, Alibaba Group Holding Limited
//

#ifndef OpCommonUtils_hpp
#define OpCommonUtils_hpp
#include <cstdint>
#include <vector>
#include <MNN/Tensor.hpp>
#include "TensorUtils.hpp"
#include "FileLoader.hpp"

namespace MNN {
struct Op;
struct CoreFunctions;
#ifdef MNN_SUPPORT_TRANSFORMER_FUSE
struct KVMeta {
    enum {
        NoChange,
        PendingWrite,
        PendingRead
    } file_operation;
    size_t block = 4096;
    size_t previous = 0;
    size_t remove = 0;
    int* reserve = nullptr;
    int n_reserve = 0;
    size_t add = 0;
    std::string file_name = "";
    int file_flag = NoChange;
    int seqlen_in_disk = 0;
    int layer_index = 0;
    int layer_nums = 0;

    // H2O runtime configuration (set by llm config).
    int h2o_enable = 0;
    int h2o_layer_start = 2;
    int h2o_layer_end = -1;
    int h2o_block_tokens = 64;
    int h2o_sink_tokens = 32;
    int h2o_recent_tokens = 256;
    float h2o_target_keep_ratio = 0.50f;
    int h2o_target_mode = 1; // 0:static keep ratio, 1:adaptive by target lossy ratio
    float h2o_target_lossy_ratio = 3.0f;
    float h2o_ema_alpha = 0.90f;
    int h2o_update_interval = 16;
    int h2o_trigger_min_tokens = 512;
    int h2o_log_stats = 0;
    int h2o_lossless_enable = 0;
    int h2o_lossless_codec = 0; // 0:none 1:gear_delta
    int h2o_lossless_scope = 1; // 0:none 1:front_n 2:h2o_kept
    int h2o_lossless_front_n = 2;
    int h2o_lossless_runtime_enable = 0;
    int h2o_lossless_runtime_mode = 0; // 0:probe(sample), 1:full
    int h2o_lossless_block_tokens = 128;
    int h2o_lossless_hot_recent_tokens = 256;
    int h2o_lossless_hot_sink_tokens = 16;
    std::string h2o_lossless_codec_runtime = "fp16_gear_predictive_v3";
    std::string h2o_lossless_predictors_k = "raw,delta_seq,xor_seq,pair_delta";
    std::string h2o_lossless_predictors_v = "raw,delta_seq,xor_seq";
    int h2o_lossless_async_threads = 1;
    int h2o_lossless_max_queue = 256;
    int h2o_lossless_decode_cache_blocks = 64;
    int h2o_lossless_strict_roundtrip_check = 0;
    int h2o_in_decode = 0;

    // Next-step pending compact plan generated by H2O.
    size_t h2o_pending_remove = 0;
    int* h2o_pending_reserve = nullptr;
    int h2o_pending_n_reserve = 0;
    int h2o_pending_plan_ready = 0;

    // Runtime stats.
    float h2o_keep_ratio = 1.0f;
    float h2o_lossy_ratio = 1.0f;
    float h2o_lossless_ratio = 1.0f;
    float h2o_target_keep_effective = 1.0f;
    float h2o_floor_keep_by_recent_sink = 1.0f;
    float h2o_block_quantized_keep = 1.0f;
    int64_t h2o_evict_us = 0;
    int64_t h2o_codec_us = 0;
    uint64_t h2o_lossless_raw_bytes = 0;
    uint64_t h2o_lossless_compressed_bytes = 0;
    uint64_t h2o_lossless_decompressed_bytes = 0;
    int64_t h2o_lossless_compress_us = 0;
    int64_t h2o_lossless_decompress_us = 0;
    int64_t h2o_lossless_queue_depth_peak = 0;
    int64_t h2o_lossless_fallback_count = 0;
    int h2o_last_evict_tokens = 0;
    int h2o_total_evict_tokens = 0;

    int computeReverseSize() const {
        int sum = 0;
        for (int i=0; i<n_reserve; ++i) {
            int reserveUnit = reserve[2*i+1];
            if (reserveUnit <= 0) {
                // Invalid
                return -1;
            }
            sum += reserveUnit;
        }
        return sum;
    }
};
#endif

class MNN_PUBLIC OpCommonUtils {
#define USE_EXTERNAL_DATA(param) (param->external() && param->external()->size() > 1)
public:
    static bool checkNet(const void* buffer, size_t length);
    static Tensor::DimensionType convertDimType(MNN_DATA_FORMAT dimensionFormat);
    static bool supportDynamicInputMemory(MNNForwardType type);
    static void broastCastComputeDim(int* dims, int* stride, int* iStride0, int* iStride1, const Tensor* input0,
                                     const Tensor* input1, const Tensor* output);
    static void unravelIndexHelper(int32_t* coordinate, const int32_t* mod, int size,
                                   int indice);
    static int computeStride(int32_t* strides, const int* shape, int length);
    static void loadBlobData(FileLoader* loader, const Op* op, char* ptr, int size);

    static bool canBlitFast(const Tensor::InsideDescribe::Region& region, const Tensor* dest, int pack = 4, bool swapnc = false, bool swapcw = false);
    static void turnToPackRegion(const Tensor::InsideDescribe::Region& region, Tensor::InsideDescribe::Region& c4Region,
                                 const Tensor* dest, int pack = 4, bool swapnc = false);

    // Inside - Axis - Outside
    typedef std::tuple<int, int, int> SPLITS;
    static bool canBlitFast(const Tensor::InsideDescribe::Region& region, const SPLITS& srcSplits,
                            const SPLITS& dstSplits, int pack = 4, bool swapnc = false, bool swapcw = false);
    static void turnToPackRegion(const Tensor::InsideDescribe::Region& region, Tensor::InsideDescribe::Region& c4Region,
                                 const SPLITS& srcSplits, const SPLITS& dstSplits, int pack = 4, bool swapnc = false);
    static bool opNeedContent(const MNN::Op* op, int index);

    // For lowp CPU Backend
    static bool opCompabilityForLowp(const Op* op, int bytes);
    
    static void rasterInputReset(const std::vector<Tensor*>& inputs, Tensor* output);

    static void loadExternalDatas(FileLoader* loader, std::vector<char*> addrs, const int64_t* external);
    struct TensorConvertParameter {
        int batch;
        int channel;
        int area;
        int type;
    };

    // Detect if the region is a convert
    static void turnRegion2Convert(const Tensor::InsideDescribe::Region& region, const Tensor* dest, TensorConvertParameter& info);

    // Detect if the region is a transpose
    static bool isTranspose(const Tensor::InsideDescribe::Region& region, int& srcOne, int& dstOne);

    static bool computeMatMulSize(bool transposeA, bool transposeB, const Tensor* A, const Tensor* B, int& e, int& l, int& h);
    static Execution* createExecutionWithExternal(Backend* backend, const std::vector<Tensor*>& inputs, const std::vector<Tensor*>& outputs,
                                                  const MNN::Op* op, FileLoader* externalFile, std::shared_ptr<BufferStorage>& tmpstore);
    static DataType convertDataType(halide_type_t type);

};
} // namespace MNN

#endif
